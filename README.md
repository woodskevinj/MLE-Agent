# ğŸ¤– MLE-Agent

**MLE-Agent** is a lightweight Machine Learning Engineering Assistant that can:

- understand natural language requests
- decide which tools to use
- execute Python code safely
- read/write files
- generate ML project scaffolds
- store and recall memory
- perform EDA and feature engineering
- train baseline ML models
- and fall back to LLM responses when needed

This project demonstrates a real-world **agent architecture**:  
**Planner â†’ Memory â†’ Executor â†’ Tools/LLM â†’ Result**

It is designed to be modular, extensible, and easy to grow into a full ML engineering assistant.

---

## âœ… Current Capabilities

### ğŸ”¹ Natural Language Planning (Planner v3)

The agent converts plain English into a sequence of executable steps:

- file read/write
- Python execution
- project scaffolding
- dataset loading and analysis
- model training
- LLM fallback

The planner understands synonyms, handles uppercase/lowercase, and supports multi-step chained commands.

### ğŸ”¹ Memory-Aware Planning (NEW)

MLE-Agent includes a full Memory Module with:

- **Episodic Memory** â€” stores tool calls, LLM responses, outcomes

- **Semantic Memory** â€” stores project facts, user preferences, and persistent knowledge

- **Automatic Recall** â€” powered by SQLite FTS5 + BM25 + recency + importance scoring

- **Planner context injection** - memory is automatically appended to the plan for richer context

Planner automatically receives:

- task-relevant memories

- recent session history

- pinned/important facts

Executor logs tool + LLM outcomes back to memory.

---

### ğŸ”¹ Implemented Tools

| Tool Name             | Description                                         |
| --------------------- | --------------------------------------------------- |
| `read_file`           | Read a text file from disk                          |
| `write_file`          | Write or overwrite a file                           |
| `run_python`          | Safely execute Python code                          |
| `generate_scaffold`   | Create starter ML project structures                |
| `load_csv`            | Load CSV datasets and preview structure             |
| `preview_data`        | Display top rows of the current dataset             |
| `describe_data`       | Show dataset statistics, missing values, and dtypes |
| `column_info`         | Display numerical vs categorical columns            |
| `encode_categoricals` | One-hot encode string columns for modeling          |
| `scale_numericals`    | Standardize numeric columns                         |
| `split_data`          | Split dataset into train/test sets                  |
| `train_model`         | Train logistic or random forest model               |
| `save_model`          | Persist trained models (auto-creates `/models`)     |

---

Planned future tools:

- ML model training helpers
- SHAP explainability modules
- Docker helpers
- AWS ECR/ECS deployment helpers

---

## âœ… Architecture Overview

**User â†’ Planner â†’ Memory Context â†’ LLM (optional plan refinement) â†’ Executor â†’ Tools/LLM â†’ Memory Logging â†’ Result**

### ğŸ§  Planner (`planner.py`)

- Rule-based intent detector

- Splits multi-step natural language into structured actions

- Supports memory context injection before execution

### ğŸ—‚ï¸ Memory Module (`agent/memory/*`)

- **store.py:** SQLite + FTS5 memory backend
- **module.py:** high-level API for remember(), recall(), context(), and recent()
- **ranking.py:** BM25 + recency + importance reranking

### âš™ï¸ Executor (`executor.py`)

- Executes tool or LLM steps
- Logs outcomes into episodic memory after every run

### ğŸ’¬ LLM Core (`core.py`)

- Wrapper around OpenAIâ€™s `client.responses.create()`
- Provides natural fallback answers for arbitrary questions

Uses OpenAIâ€™s modern API:

```python
client.responses.create(model="gpt-4o-mini", input="...")
```

---

## ğŸ§ª EDA + Feature Engineering Tools

**Located in:** `tools/eda_tools.py` and `tools/feature_tools.py`

| Function                | Description                               |
| ----------------------- | ----------------------------------------- |
| `load_csv(path)`        | Loads dataset into memory                 |
| `preview_data(n)`       | Shows first _n_ rows                      |
| `describe_data()`       | Summary stats + missing values + dtypes   |
| `column_info()`         | Lists numeric and categorical columns     |
| `encode_categoricals()` | One-hot encodes categorical columns       |
| `scale_numericals()`    | Standard-scales numeric features          |
| `split_data()`          | Splits dataset into training/testing sets |
| `save_dataframe(path)`  | Saves the transformed dataset to disk     |

These tools prepare your data for downstream modeling directly through the agent pipeline.

---

## ğŸ¤– ML Training Tools

**Located in:** `tools/ml_tools.py`

| Function                                                   | Description                                        |
| ---------------------------------------------------------- | -------------------------------------------------- |
| `train_model(state, label="Churn", model_type="logistic")` | Trains logistic regression or random forest models |
| `evaluate_model(state, path=None)`                         | Evaluates a cached or saved model                  |
| `save_model(state, path="models/model.pkl")`               | Saves trained model to the `/models` folder        |

**Example Run**

```bash
python -m scripts.test_ml_tools
```

Output:

```bash
Model trained successfully (logistic).
Accuracy: 0.8084
Confusion Matrix:
[[958  78]
 [192 181]]
Classification Report:
...
Model saved to models/churn_logreg.pkl
```

---

## âœ… Memory Example

```bash
USER: Run python: print(5*5)

USER: What did I run earlier?
RESULT: Based on memory: You ran print(5*5) and the output was 25.
```

---

## âœ… Data + Feature Example

```bash
USER: load csv file data/telco/WA_Fn-UseC_-Telco-Customer-Churn.csv
USER: encode categoricals
USER: scale numericals
USER: split data
USER: save dataframe to data/telco/transformed.csv
```

---

## ğŸ—‚ï¸ Project Structure

```bash
MLE-Agent/
â”‚
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ agent.py                 # Main agent orchestrator
â”‚   â”œâ”€â”€ core.py                  # LLM wrapper (OpenAI SDK)
â”‚   â”œâ”€â”€ planner.py               # Natural language planner (v3)
â”‚   â”œâ”€â”€ executor.py              # Executes tools & LLM plans
â”‚   â”œâ”€â”€ tools.py                 # Central tool registry
â”‚   â”œâ”€â”€ debug.py                 # Debug mode + log helper
â”‚   â””â”€â”€ memory/                  # Memory subsystem
â”‚       â”œâ”€â”€ module.py            # High-level memory interface
â”‚       â”œâ”€â”€ store.py             # SQLite + FTS5 memory backend
â”‚       â”œâ”€â”€ models.py            # Memory object schema
â”‚       â”œâ”€â”€ ranking.py           # BM25 + recency + importance scoring
â”‚       â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ file_tools.py            # File read/write helpers
â”‚   â”œâ”€â”€ python_tools.py          # Safe Python execution
â”‚   â”œâ”€â”€ project_tools.py         # Project scaffold generator
â”‚   â”œâ”€â”€ eda_tools.py             # Data loading, preview, describe
â”‚   â”œâ”€â”€ feature_tools.py         # Feature engineering utilities
â”‚   â””â”€â”€ ml_tools.py              # Model training & evaluation
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ test_agent_local.py      # Planner + Executor integration test
â”‚   â”œâ”€â”€ test_multistep.py        # Multi-step natural language chain
â”‚   â”œâ”€â”€ test_feature_tools.py    # Feature engineering test
â”‚   â”œâ”€â”€ test_ml_tools.py         # ML training pipeline test
â”‚   â”œâ”€â”€ test_memory_smoke.py     # Memory system smoke test
â”‚   â”œâ”€â”€ run_agent.py             # CLI-based entry for agent
â”‚   â””â”€â”€ cli_demo.py              # Interactive terminal demo
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_agent.py            # Unit tests for plan_


```

---

## âœ… Requirements

Make sure you have:

1. Python 3.10+

2. Virtual environment activated

3. Install dependencies:

```bash
pip install -r requirements.txt
```

4. Set your OpenAI API key (https://platform.openai.com/api-keys):

```bash
export OPENAI_API_KEY="your-key"
```

---

## âœ… Roadmap

| Stage               | Description                         | Status |
| ------------------- | ----------------------------------- | ------ |
| Planner v3          | Multi-step natural language planner | âœ…     |
| Memory Module       | Episodic + semantic recall          | âœ…     |
| EDA Tools           | Dataset loading and exploration     | âœ…     |
| Feature Tools       | Encoding, scaling, splitting        | âœ…     |
| ML Tools            | Model training and saving           | âœ…     |
| Explainability      | SHAP and model insights             | ğŸ”œ     |
| FastAPI Endpoint    | `/agent/query` for API use          | ğŸ”œ     |
| Docker / ECS Deploy | Containerized endpoint              | ğŸ”œ     |

---

## ğŸš€ Status

MLE-Agent is now a memory-enabled ML assistant with:

âœ… Natural language planning

âœ… Memory-aware reasoning

âœ… EDA + feature engineering

âœ… Model training + saving

âœ… Clean modular design

A strong foundation for building a true Applied ML Engineering Agent.

---

## ğŸ‘¨â€ğŸ’» Author

### Kevin Woods

Applied ML Engineer

AWS Certified AI Practitioner

AWS Machine Learning Certified Engineer â€“ Associate

- ğŸ”— [GitHub: woodskevinj](https://github.com/woodskevinj)
