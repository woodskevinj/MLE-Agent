# ğŸ¤– MLE-Agent

**MLE-Agent** is a lightweight Machine Learning Engineering Assistant that can:

- understand natural language requests
- decide which tools to use
- execute Python code safely
- read/write files
- generate ML project scaffolds
- store and recall memory
- and fall back to LLM responses when needed

This project demonstrates a real-world **agent architecture**:  
**Planner â†’ Memory â†’ Executor â†’ Tools/LLM â†’ Result**

It is designed to be modular, extensible, and easy to grow into a full ML engineering assistant.

---

## âœ… Current Capabilities

### ğŸ”¹ Natural Language Planning (Planner v3)

The agent converts plain English into a sequence of executable steps. Examples:

- file read/write

- Python execution

- Project scaffolding

- LLM fallback

The planner understands synonyms, handles uppercase/lowercase, and supports multi-step chained commands.

### ğŸ”¹ Memory-Aware Planning (NEW)

MLE-Agent now includes a full Memory Module with:

- **Episodic Memory**:

  Stores tool calls, LLM responses, errors, outcomes.

- **Semantic Memory**:

  Stores long-lived knowledge like project details, user preferences, or environment rules.

- **Automatic recall**:

  Memory is retrieved via SQLite FTS5 (BM25 ranking) + recency + importance scoring.

- **Planner Context Injection**:
  When the user issues a new request, Planner automatically receives a memory_context block containing:

  - task-relevant memories

  - recent agent history

  - pinned or high-importance facts

This makes the agent more stable across sessions and more capable of multi-step reasoning.

---

### ğŸ”¹ Implemented Tools

| Tool Name           | Description                                     |
| ------------------- | ----------------------------------------------- |
| `read_file`         | Read a text file from disk                      |
| `write_file`        | Write or overwrite a file                       |
| `run_python`        | Safely execute Python code (isolated namespace) |
| `generate_scaffold` | Create starter ML project structures            |

Planned future tools:

- EDA utilitites
- ML model training helpers
- SHAP explainability modules
- Docker helpers
- AWS ECR/ECS deployment helpers

---

## âœ… Architecture Overview

User â†’ Planner â†’ **Memory Context** â†’ LLM (optional plan refinement) â†’ Executor â†’ Tools/LLM â†’ **Memory Logging** â†’ Result

### **Planner (planner.py)**

- Rule-based intent detector

- Splits multi-step language into structured actions

- Detects known tool actions

- Falls back to LLM when no pattern matches

- Now includes memory_context for richer planning

### **Memory Module (agent/memory/\*)**

- store.py: SQLite FTS5 memory backend

- models.py: Memory objects (episodic, semantic)

- ranking.py: BM25 + recency + importance reranking

- module.py: High-level memory API:

  - remember()

  - recall()

  - context()

  - recent()

Planner uses memory.context() before forming a plan.

Executor logs all outcomes back into memory.

### **Executor (executor.py)**

- Executes tool actions or LLM responses

- Feeds results into the next step

- Logs episodic memories after every tool or LLM output

### **LLM Core (core.py)**

Simple interface around OpenAIâ€™s SDK using:

```python
client.responses.create(model="gpt-4o-mini", input="...")
```

---

## âœ… Memory Example

```bash
USER: Run python: print(5*5)

USER: What did I run earlier?
RESULT: Based on memory: You ran print(5*5) and the output was 25.
```

---

## âœ… Project Structure

```bash
MLE-Agent/
â”‚
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ agent.py
â”‚   â”œâ”€â”€ core.py
â”‚   â”œâ”€â”€ planner.py
â”‚   â”œâ”€â”€ executor.py
â”‚   â”œâ”€â”€ tools.py
â”‚   â”œâ”€â”€ debug.py
â”‚   â””â”€â”€ memory/
â”‚       â”œâ”€â”€ module.py
â”‚       â”œâ”€â”€ store.py
â”‚       â”œâ”€â”€ models.py
â”‚       â”œâ”€â”€ ranking.py
â”‚       â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ file_tools.py
â”‚   â”œâ”€â”€ python_tools.py
â”‚   â””â”€â”€ project_tools.py
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ test_agent_local.py
â”‚   â”œâ”€â”€ test_multistep.py
â”‚   â”œâ”€â”€ run_agent.py
â”‚   â””â”€â”€ cli_demo.py
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_agent.py
â”‚   â”œâ”€â”€ test_tools.py
â”‚   â””â”€â”€ test_end_to_end.py
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## âœ… Requirements

Make sure you have:

1. Python 3.10+

2. Virtual environment activated

3. Install dependencies:

```bash
pip install -r requirements.txt
```

4. Set your OpenAI API key (https://platform.openai.com/api-keys):

```bash
export OPENAI_API_KEY="your-key"
```

---

## âœ… Roadmap

### Next Steps (coming up next)

âœ… Multi-step tool chaining

âœ… Planner v3 (synonyms, case-insensitive, code-preserving)

âœ… Executor v2

âœ… Python + file I/O tools

âœ… Project scaffold tool

âœ… Memory Module (episodic + semantic)

âœ… Memory-aware planning & recall

### Coming Next

â¬œ ML/EDA tools

â¬œ SHAP explainability

â¬œ Dataset analysis

â¬œ FastAPI agent endpoint (/agent/query)

â¬œ Vector search memory (embeddings)

â¬œ Tool self-reflection

â¬œ Docker containerization

â¬œ AWS ECR/ECS agent deploy option

---

## ğŸš€ Status

MLE-Agent is now a memory-enabled agent framework with:

âœ… Natural language intent detection

âœ… Multi-step planning

âœ… Memory-aware context

âœ… Tool routing

âœ… Python execution

âœ… File operations

âœ… Project generation

âœ… LLM fallback

âœ… Clean architecture

A strong foundation for building a **true ML engineering assistant**.

---

## ğŸ‘¨â€ğŸ’» Author

### Kevin Woods

Applied ML Engineer

AWS Certified AI Practitioner

AWS Machine Learning Certified Engineer â€“ Associate

- ğŸ”— [GitHub: woodskevinj](https://github.com/woodskevinj)
